{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0df9a85c",
   "metadata": {},
   "source": [
    "# Billion-scale connected components with üçáüçá GRAPE üçáüçá\n",
    "In this tutorial, I will show you how to use the [GRAPE library](https://github.com/AnacletoLAB/grape) to compute the connected components of a graph, which are groups of nodes that are connected to each other by a path. This is a useful problem to solve in many applications, and is an essential step in graph quality control.\n",
    "\n",
    "I will discuss some of the basics of graph analysis and introduce key concepts such as quality control, computational complexity, and depth-first search. I will also briefly touch the concept of graph neural networks.\n",
    "\n",
    "I will then briefly explain what are parallel work-stealing algorithms, and some brief details on the connected components algorithm available in GRAPE.\n",
    "\n",
    "By the end of the tutorial, you will have a good understanding of how to use GRAPE to compute the connected components of a graph and apply this knowledge to your own projects.\n",
    "\n",
    "[Remember to ‚≠ê GRAPE!](https://github.com/AnacletoLAB/grape)\n",
    "\n",
    "## First, some basics!\n",
    "This section provides an overview of quality control, computational complexity, graphs, breadth-first search, and graph neural networks. We also touch upon graph convolutional networks, a type of neural network for processing graph-structured data. **If you are already familiar with these concepts, feel free to skip this section.**\n",
    "\n",
    "### Quality control\n",
    "Quality control of datasets is the process of ensuring that the data used for various purposes is accurate, reliable, and relevant. It involves checking the data for completeness, accuracy, and consistency, and correcting or removing any errors or inconsistencies that may be present. Quality control of datasets is important because the quality of the data has a direct impact on the accuracy and reliability of the results obtained from the data. Poor quality data can lead to incorrect conclusions, which can have serious consequences in fields such as healthcare, finance, and scientific research. Ensuring the quality of datasets is therefore essential for ensuring the integrity and reliability of the results obtained from the data. [We have already learned how to create an extensive quality control report for graphs in this other GRAPE tutorial](https://github.com/AnacletoLAB/grape/blob/main/tutorials/Create%20extensive%20knowledge%20graph%20reports%20using%20GRAPE.ipynb)\n",
    "\n",
    "### Computational complexity\n",
    "[Computational complexity](https://en.wikipedia.org/wiki/Computational_complexity) refers to the amount of resources (e.g., time, space) required by an algorithm to solve a problem. It is typically measured in terms of the size of the input data. Worst-case complexity refers to the maximum amount of resources required by the algorithm over all possible inputs of a given size. This measure is useful because it provides a guarantee on the performance of the algorithm, regardless of the specific input data. However, it may not accurately reflect the average performance of the algorithm on typical input data.\n",
    "\n",
    "### What is a graph\n",
    "[A graph](https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)) is a data structure that consists of a set of vertices, or nodes, and a set of edges connecting these vertices. Graphs are used to represent relationships between different entities in a wide range of applications, such as social networks, transportation systems, and biological networks.\n",
    "\n",
    "Some graphs can be very large, with millions or even billions of vertices and edges. The size of a graph can significantly impact the performance of algorithms used to analyze or process it. Therefore, it is important to develop efficient algorithms for analyzing large graphs.\n",
    "\n",
    "### Breadth-first search\n",
    "[Breadth-first search (BFS)](https://en.wikipedia.org/wiki/Breadth-first_search) is an algorithm for traversing or searching a graph, tree, or other data structure. It starts at a given node (called the root or starting node) and explores as far as possible along each branch before backtracking.\n",
    "\n",
    "The algorithm starts by placing the root node in a queue, which is a first-in, first-out data structure. It then repeatedly removes the first node from the queue, examines it, and adds its neighbors to the end of the queue. By repeating this process, the algorithm visits all the nodes in the graph in a specific order, called a breadth-first traversal.\n",
    "\n",
    "BFS has a number of applications, including finding the shortest path between two nodes in a graph and checking if a graph is connected. It is also used as a building block for other algorithms, such as topological sorting and network connectivity analysis.\n",
    "\n",
    "### Graph neural networks\n",
    "[Graph neural networks (GNNs)](https://www.cs.mcgill.ca/~wlh/grl_book/) are a class of neural networks that are specifically designed to process graph-structured data. They have been applied to a variety of tasks including node classification, link prediction, and graph classification. GNNs are particularly useful for tasks that involve the analysis of relationships between entities in a graph, as they are able to incorporate the graph structure in their learning process.\n",
    "\n",
    "#### Graph convolutional networks\n",
    "[Graph convolutional networks (GCNs)](https://arxiv.org/pdf/1609.02907.pdf) are a type of neural network designed specifically to operate on graph-structured data. Like traditional convolutional neural networks, GCNs use convolutional layers to process and analyze data. However, rather than operating on grid-structured data such as images, GCNs perform convolutions on the graph structure itself, using the relationships between nodes in the graph as the basis for their analysis. GCNs have been successfully applied to a wide range of tasks in domains such as computer vision, natural language processing, and drug discovery, and have been shown to outperform traditional methods on many graph-based problems.\n",
    "\n",
    "### Parallel algorithms\n",
    "A [parallel algorithm](https://en.wikipedia.org/wiki/Parallel_algorithm) is a type of algorithm that is designed to be executed concurrently on multiple processors or computing devices in order to solve a problem faster than a sequential algorithm. Parallel algorithms are often used to solve problems that are too large or complex to be efficiently solved by a single processor, and they rely on the fact that modern computers often have multiple processors or cores that can be used to execute tasks concurrently.\n",
    "\n",
    "There are many different types of parallel algorithms, including divide-and-conquer algorithms, which divide the problem into smaller subproblems that can be solved independently; and data parallel algorithms, which operate on multiple data items concurrently. Parallel algorithms can also be classified based on the type of parallelism they use, such as task parallelism, which involves executing different tasks concurrently; or data parallelism, which involves operating on multiple data items concurrently.\n",
    "\n",
    "To design and implement a parallel algorithm, it is often necessary to consider factors such as the amount of parallelism available, the communication and **synchronization** requirements of the algorithm, and the **overhead associated with dividing the problem into smaller pieces and coordinating the execution of the algorithm on multiple processors**.\n",
    "\n",
    "### What is GRAPE?\n",
    "[üçáüçá GRAPE üçáüçá](https://github.com/AnacletoLAB/grape) is a graph processing and embedding library that enables users to easily manipulate and analyze graphs. With [GRAPE](https://github.com/AnacletoLAB/grape), users can efficiently load and preprocess graphs, generate random walks, and apply various node and edge embedding models. Additionally, [GRAPE](https://github.com/AnacletoLAB/grape) provides a fair and reproducible evaluation pipeline for comparing different graph embedding and graph-based prediction methods.\n",
    "\n",
    "![GRAPE](https://github.com/AnacletoLAB/grape/raw/main/images/sequence_diagram.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e666f1e",
   "metadata": {},
   "source": [
    "## What is a connected component?\n",
    "[A connected component](https://en.wikipedia.org/wiki/Component_(graph_theory)) in a graph is a subset of the vertices such that there is a path between any two vertices in the subset. In other words, you can reach any vertex in the subset from any other vertex in the subset by following the edges of the graph. A connected component is also a maximal subgraph, meaning that it is not possible to add any more vertices to the connected component without including vertices from outside of it.\n",
    "\n",
    "<img src=\"https://github.com/AnacletoLAB/grape/blob/main/images/connected_components.png?raw=true\" width=300 />\n",
    "\n",
    "### How can connected components be used for quality control? \n",
    "\n",
    "Connected components can be useful for quality control of graphs in several ways:\n",
    "\n",
    "* **Verifying connectivity**: Connected components can be used to check whether a graph is connected or not. A graph is considered connected if there is a path between any two vertices in the graph. If a graph has more than one connected component, it is not considered connected.\n",
    "\n",
    "* **Identifying errors**: Connected components can also be used to identify errors in a graph. For example, if a graph is supposed to be fully connected but has multiple connected components, there may be an error in the way the graph was constructed.\n",
    "\n",
    "* **Removing disconnected vertices**: In some cases, it may be necessary to remove disconnected vertices from a graph. Connected components can be used to identify these vertices and remove them if needed.\n",
    "\n",
    "* **Filtering data**: Connected components can also be used to filter data in a graph. For example, if you are interested in analyzing only the largest connected component in a graph, you can use connected components to identify and extract that component.\n",
    "\n",
    "Overall, connected components can be a useful tool for quality control of graphs by helping to identify errors, remove disconnected vertices, and filter data as needed.\n",
    "\n",
    "## A parallel work-stealing algorithm for connected components\n",
    "\n",
    "The parallel work-stealing algorithm from GRAPE we are going to use is one developed by [Luca Cappelletti](https://www.linkedin.com/in/luca-cappelletti-364a25119/) and [Tommaso Fontana](https://www.linkedin.com/in/tommaso-fontana/) by building on top of the one presented in [\"A Fast, Parallel Spanning Tree Algorithm for Symmetric\n",
    "Multiprocessors (SMPs)\"](https://smartech.gatech.edu/bitstream/handle/1853/14355/GT-CSE-06-01.pdf). We are going to discuss the performance of the thread-stealing [spanning arborescenses](https://en.wikipedia.org/wiki/Arborescence_(graph_theory)) algorithm in a future tutorial, which is already available in GRAPE.\n",
    "\n",
    "This algorithm is able to execute without significant synchronization steps on graphs with both regular and irregular topologies. On large inputs, it appears to have a runtime that decreases linearly with the number of processors. Based on this and [Bader and Cong's algorithm](https://smartech.gatech.edu/bitstream/handle/1853/14355/GT-CSE-06-01.pdf), one can surely identify and implement many other derivative use cases that may benefit of this work-stealing approach.\n",
    "\n",
    "This algorithm is efficient because of the implementative details, and detailing this algorithm in a pseudocode would only be detrimental to the understanding of how such class of algorithms works. I suggest you proceed to read the source code, [which is available here](https://github.com/AnacletoLAB/ensmallen/blob/1191de67bf68a6aeecb625faf80e2b3aa62f17a0/graph/src/trees.rs#L563).\n",
    "\n",
    "### Work-stealing algorithms\n",
    "A [work-stealing algorithm](https://en.wikipedia.org/wiki/Work_stealing) is a parallel programming technique that is used to dynamically balance the workload among multiple processors or threads in a computer system. It works by having each processor or thread maintain a queue of tasks that need to be completed, and if a processor runs out of tasks to work on, it can \"steal\" tasks from the queue of another processor that still has tasks remaining.\n",
    "\n",
    "The basic idea behind work-stealing is to allow processors to work independently on their own tasks as much as possible, but to also provide a mechanism for redistributing work when one processor becomes idle while others are still busy. This can help to improve the overall performance of the system by ensuring that all processors are kept busy and that the workload is evenly distributed.\n",
    "\n",
    "Work-stealing algorithms can be particularly useful in situations where the workload is not evenly distributed among the processors, or when the work can be decomposed into smaller tasks that can be executed independently.\n",
    "\n",
    "**In graphs, often, the work relative to processing a high-degree node is much more intensive than one for processing a low-degree node.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de848e2",
   "metadata": {},
   "source": [
    "## Installing GRAPE\n",
    "First, we install the GRAPE library from PyPI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e5462cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install grape -qU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4c963f",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "Welcome to the experiments section of this tutorial! In this section, we will put our knowledge into practice by applying the work-stealing parallel connected components algorithm to compute the connected components of four different graphs: the [KGCOVID19 knowledge graph](https://www.cell.com/patterns/fulltext/S2666-3899(20)30203-8?_returnURL=https%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS2666389920302038%3Fshowall%3Dtrue), the [Friendter graph](https://networkrepository.com/friendster.php), the [ClueWeb09 web graph](https://networkrepository.com/web-ClueWeb09.php), and [the WikiData graph](https://www.wikidata.org/wiki/Wikidata:Main_Page).\n",
    "\n",
    "We run these experiments on a machine with 24 threads and 12 cores.\n",
    "\n",
    "**Do note that, for limits of memory of my desktop, I will restart the jupyter after running the experiment on each of the large graphs.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15280e49",
   "metadata": {},
   "source": [
    "### KGCOVID19\n",
    "We kick off our experiments with a rather small graph, considering the sizes of the networks we are going to tackle by the end of it: KGCOVID19, with `574K` nodes and `18M` edges.\n",
    "\n",
    "#### What is KGCOVID19?\n",
    "[KGCOVID19](https://doi.org/10.1016%2Fj.patter.2020.100155) is a framework for producing knowledge graphs (KGs) that integrate and integrate biomedical data related to the COVID-19 pandemic. The framework is designed to be flexible and customizable, allowing researchers to create KGs for different downstream applications including machine learning tasks, hypothesis-based querying, and browsable user interfaces for exploring and discovering relationships in COVID-19 data. The goal of KGCOVID19 is to provide an up-to-date, integrated source of data on SARS-CoV-2 and related viruses, including SARS-CoV and MERS-CoV, to support the biomedical research community in its efforts to respond to the COVID-19 pandemic. The framework can also be applied to other situations in which siloed biomedical data must be quickly integrated for various research purposes, including future pandemics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c0b685e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.7 s, sys: 3.32 s, total: 29 s\n",
      "Wall time: 8.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from grape.datasets.kghub import KGCOVID19\n",
    "\n",
    "kgcovid19 = KGCOVID19()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5901df14",
   "metadata": {},
   "source": [
    "We display the number of nodes, `574K` and of undirected edges `18M`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "878ffc06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(574232, 18251238)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kgcovid19.get_number_of_nodes(), kgcovid19.get_number_of_edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55921909",
   "metadata": {},
   "source": [
    "And now we compute the connected components. It should be pretty much instantenous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c35198a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.75 s, sys: 388 ms, total: 4.14 s\n",
      "Wall time: 186 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "(\n",
    "    connected_component_ids_per_node,\n",
    "    number_of_connected_components,\n",
    "    smallest_component_size, \n",
    "    largest_component_size\n",
    ") = kgcovid19.get_connected_components()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01318e7e",
   "metadata": {},
   "source": [
    "Here are the component IDS for each of the nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "109a6118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     0,     0, ..., 30292,     0, 30469], dtype=uint32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connected_component_ids_per_node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265915b9",
   "metadata": {},
   "source": [
    "This graph contains many connected components, with a huge portion of them being singleton nodes, or tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cace1a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30984"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_connected_components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afde05fa",
   "metadata": {},
   "source": [
    "The smallest component is indeed a singleton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1da39bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smallest_component_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc54c9b0",
   "metadata": {},
   "source": [
    "And the principal component, the largest one, has indeed most of the nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5dc730c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "540067"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "largest_component_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3270c2a9",
   "metadata": {},
   "source": [
    "### Friendster\n",
    "[Friendster](https://en.wikipedia.org/wiki/Friendster) was a social networking service launched in 2002. It was one of the first social networking sites, and was popular in the early 2000s. The site allowed users to connect with friends and meet new people through the use of personal profiles and networks of friends. Friendster was initially successful, but it eventually faced competition from newer social networking sites such as MySpace and Facebook. In 2011, the company announced that it was transitioning from a social networking site to a social gaming site, and in 2015 it was acquired by a Malaysian company.\n",
    "\n",
    "#### What is network repository?\n",
    "[Network Repository](https://networkrepository.com/index.php) is a scientific network data repository that provides interactive visualization and mining tools for analyzing and exploring network data. It is the first interactive repository of its kind and is also the largest network repository, containing thousands of network data sets in over 30 domains, including biological, social, and machine learning data. The repository allows users to visualize and explore network data sets, view interactive statistics and plots, and download massive network data sets with billions of edges. It also includes a visual analytics platform called GraphVis, which allows users to interactively analyze and explore network data in real-time over the web and use it for educational purposes. Network Repository is intended to facilitate scientific research on networks by making it easier for researchers to access and analyze a large collection of network data. It is a valuable resource for researchers in a variety of fields, including network science, bioinformatics, machine learning, data mining, physics, and social science."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f30b201",
   "metadata": {},
   "source": [
    "#### ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è WARNING: Make sure you have enough disk space! ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è\n",
    "*Please be aware that this graph is not small and requires a significant amount of disk space to store and work with. Before proceeding with the tutorial, make sure that you have enough free space on your hard drive or other storage device to accommodate the size of the graph. If you do not have sufficient space, you may encounter errors or other issues when attempting to download or work with the graph. It is important to ensure that you have enough space available before proceeding. If necessary, consider freeing up additional space on your device to make room for the graph.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afafaae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97G\t/bfd/graphs/networkrepository/SocFriendster\r\n"
     ]
    }
   ],
   "source": [
    "!du -sh /bfd/graphs/networkrepository/SocFriendster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f15366b",
   "metadata": {},
   "source": [
    "In the next cell we retrieve and load the Friendster dataset from GRAPE, dataset from the [network repository](https://networkrepository.com/index.php).. Do note that we are configuring it to not load the node names and edge types in order to conserve memory. The cell also includes a directive to measure and display the execution time of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb5927ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42min 13s, sys: 1min 49s, total: 44min 2s\n",
      "Wall time: 5min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from grape.datasets.networkrepository import SocFriendster\n",
    "\n",
    "friendster = SocFriendster(\n",
    "    # We cannot load the node names, as the would require too much memory\n",
    "    # for my poor old desktop.\n",
    "    load_nodes=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30f59e5",
   "metadata": {},
   "source": [
    "We display the number of nodes, `65.6M`, and of undirected edges, `1.8G`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdbee4bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65608366, 1806067135)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "friendster.get_number_of_nodes(), friendster.get_number_of_edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d0a392",
   "metadata": {},
   "source": [
    "And now we compute the connected components. In this graph, the work-stealing scales in a fantastic manner and it completes in no time at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4000078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 7s, sys: 54.2 s, total: 8min 1s\n",
      "Wall time: 21.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "(\n",
    "    connected_component_ids_per_node,\n",
    "    number_of_connected_components,\n",
    "    smallest_component_size,\n",
    "    largest_component_size,\n",
    ") = friendster.get_connected_components()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efebc134",
   "metadata": {},
   "source": [
    "Here are the component IDS for each of the nodes, which since the graph is a single connected component it is a bit tautological: all nodes have ID zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd8ee97e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=uint32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connected_component_ids_per_node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa782ad",
   "metadata": {},
   "source": [
    "The graph has a single connected component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2811a921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_connected_components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd68b7f",
   "metadata": {},
   "source": [
    "The smallest component size and the largest component size are identical, as the graph has only a single connected component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6a93000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65608366"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smallest_component_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a701a1c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65608366"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "largest_component_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5074f7bb",
   "metadata": {},
   "source": [
    "### ClueWeb\n",
    "[The ClueWeb09 dataset](http://lemurproject.org/clueweb09/) was created to support research on information retrieval and related human language technologies; it consists of about `1.7` billion web pages that were collected in January and February 2009 and the roughly `8` billion undirected links.\n",
    "\n",
    "It is used for research on information retrieval and related human language technologies and is used by several tracks of the TREC conference. The dataset includes web pages in various languages and a web graph that includes unique URLs and total outlinks for the entire dataset and for a subset called TREC Category B (the first 50 million English pages). The ClueWeb09 dataset and subsets are distributed in different formats, including as tarred/gzipped files on hard disk drives and as a subset that is downloaded from the web. The Lemur Project provides online services for searching and interacting with the ClueWeb09 dataset, including an Indri search engine for searching the English and Japanese subsets and Wikipedia, as well as a batch query service and an attribute lookup service. The Lemur Project also offers hosted copies of the ClueWeb09 dataset for organizations that have licenses to use it.\n",
    "\n",
    "*We also retrieve this graph from [Network Repository](https://networkrepository.com/index.php)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4ca962",
   "metadata": {},
   "source": [
    "#### ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è This is a big graph! Make sure you have the disk space! ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è\n",
    "*This is a warning to ensure that users have sufficient disk space available before attempting to download and use a large graph. It is important to ensure that you have enough space on your hard drive or other storage device to accommodate the size of the graph, as attempting to download or work with a graph that is too large for your available space can lead to errors and other issues. It is advisable to check your available disk space before attempting to download or work with a large graph, and to free up additional space if necessary.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a437d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "631G\t/bfd/graphs/networkrepository/WebClueweb09/\r\n"
     ]
    }
   ],
   "source": [
    "!du -sh /bfd/graphs/networkrepository/WebClueweb09/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9525bb",
   "metadata": {},
   "source": [
    "In the following cell we retrieve and load the `Clueweb09` dataset from the [network repository](https://networkrepository.com/index.php). We configure it to not load the node names in order to conserve memory. The cell also includes a directive to measure and display the execution time of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e6a8aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2h 56min 49s, sys: 8min 2s, total: 3h 4min 52s\n",
      "Wall time: 37min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from grape.datasets.networkrepository import WebClueweb09\n",
    "\n",
    "clueweb = WebClueweb09(\n",
    "    # We cannot load the node names, as the would require too much memory\n",
    "    # for my poor old desktop.\n",
    "    load_nodes=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0743a6c8",
   "metadata": {},
   "source": [
    "We display the number of nodes, `1.68G`, and of undirected edges, `7.8G`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ea0be87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1684868322, 7811385827)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clueweb.get_number_of_nodes(), clueweb.get_number_of_edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1198087a",
   "metadata": {},
   "source": [
    "And now we compute the connected components. In this particular graph, even though it is colossal, the connected components algorithm is able to distribute the load efficiently across the 24 threads and complete in about 5 minutes with minimal synchronization steps required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45575c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 51min 38s, sys: 10min 21s, total: 2h 1min 59s\n",
      "Wall time: 5min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "(\n",
    "    connected_component_ids_per_node,\n",
    "    number_of_connected_components,\n",
    "    smallest_component_size,\n",
    "    largest_component_size,\n",
    ") = clueweb.get_connected_components()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce12903e",
   "metadata": {},
   "source": [
    "Here are the component IDS for each of the nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1585801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     0,      0,      0, ...,      0, 669799, 669799], dtype=uint32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connected_component_ids_per_node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dffc0a",
   "metadata": {},
   "source": [
    "This graph contains many connected components, with a huge portion of them being singleton nodes, or tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e69ceaf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5642809"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_connected_components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2971f53",
   "metadata": {},
   "source": [
    "The smallest connected component is a tuple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16d39cef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smallest_component_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb2e1e4",
   "metadata": {},
   "source": [
    "And the largest connected component contains most of the nodes in the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd6e3ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1592230585"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "largest_component_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c84125c",
   "metadata": {},
   "source": [
    "## WikiData\n",
    "[WikiData](https://www.wikidata.org/wiki/Wikidata:Main_Page) is a collaborative, multilingual, free knowledge base that can be read and edited by humans and machines. It provides structured data that represents the relationships between concepts and entities, including real-world objects, events, and ideas, as well as abstract concepts. The data in WikiData is organized into a graph structure, with nodes representing concepts or entities and edges representing relationships between them. For example, a node for the concept \"dog\" might be connected to other nodes representing specific dog breeds, such as \"Labrador Retriever\" or \"Poodle,\" through edges that represent the relationship \"breed of.\"\n",
    "\n",
    "The WikiData graph is constantly growing and changing as users contribute new data and edit existing data. It is based on a flexible data model that allows for the creation of new properties and classes to represent the relationships between concepts and entities. The data in the WikiData graph is available for free and can be accessed through a variety of methods, including the WikiData API, SPARQL queries, and third-party tools and services. The WikiData graph is used in a variety of applications, including data integration, natural language processing, and machine learning. It is also used to provide structured data for Wikipedia and other Wikimedia projects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3f7fe8",
   "metadata": {},
   "source": [
    "#### ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è This is a big graph! Make sure you have the disk space! ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è\n",
    "*This is a warning to ensure that users have sufficient disk space available before attempting to download and use a large graph. It is important to ensure that you have enough space on your hard drive or other storage device to accommodate the size of the graph, as attempting to download or work with a graph that is too large for your available space can lead to errors and other issues. It is advisable to check your available disk space before attempting to download or work with a large graph, and to free up additional space if necessary.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8010181d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,7T\t/bfd/graphs/wikidata/WikiData\r\n"
     ]
    }
   ],
   "source": [
    "!du -sh /bfd/graphs/wikidata/WikiData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab979081",
   "metadata": {},
   "source": [
    "In the next cell we retrieve and load the WikiData dataset from GRAPE, directly from [WikiData's website](https://www.wikidata.org/wiki/Wikidata:Main_Page). Do note that we are configuring it to not load the node names and edge types in order to conserve memory. The cell also includes a directive to measure and display the execution time of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1b8b27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 55min 3s, sys: 5min 26s, total: 2h 30s\n",
      "Wall time: 20min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from grape.datasets.wikidata import WikiData\n",
    "\n",
    "wikidata = WikiData(\n",
    "    # We cannot load the node names, as the would require too much memory\n",
    "    # for my poor old desktop.\n",
    "    load_nodes=False,\n",
    "    # Same thing for the edge types.\n",
    "    load_edge_types=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033dc051",
   "metadata": {},
   "source": [
    "We display the number of nodes, `1.29G` and of undirected edges `5G`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ee9bc66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1294126247, 5040170396)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikidata.get_number_of_nodes(), wikidata.get_number_of_edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714b43a1",
   "metadata": {},
   "source": [
    "And now we compute the connected components. In this graph, even though it is also colossal, the connected components algorithm is able to distribute the load efficiently across the 24 threads and complete in about four minutes with minimal synchronization steps required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "692c5296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 24min 26s, sys: 7min 55s, total: 1h 32min 21s\n",
      "Wall time: 4min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "(\n",
    "    connected_component_ids_per_node,\n",
    "    number_of_connected_components,\n",
    "    smallest_component_size,\n",
    "    largest_component_size,\n",
    ") = wikidata.get_connected_components()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec87e17",
   "metadata": {},
   "source": [
    "Here are the component IDS for each of the nodes, which since the graph is a single connected component it is a bit tautological: all nodes have ID zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c46a758a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=uint32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connected_component_ids_per_node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26046b98",
   "metadata": {},
   "source": [
    "The graph has a single connected component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84836979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_connected_components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0941723",
   "metadata": {},
   "source": [
    "The smallest component size and the largest component size are identical, as the graph has only a single connected component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "485c84a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1294126247"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smallest_component_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "209b83ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1294126247"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "largest_component_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94c3cab",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "In this tutorial, we learned how to use the GRAPE library to compute the connected components of large graphs. We started by discussing some basic concepts of graph analysis, including quality control, computational complexity, and breadth-first search. We briefly touched upon the concept of graph neural networks and discussed what parallel work-stealing algorithms are, and how we could deploy one to compute connected components of large graphs. We proceeded to compute the connected components of four different graphs: the KGCOVID19 knowledge graph, Friendster, ClueWeb09, and WikiData. In all graphs, the algorithm completed very quickly, roughly in five minutes tops!\n",
    "\n",
    "You should now have a good understanding of how scalable GRAPE's implementation of connected components is, and how to use it!\n",
    "\n",
    "Do feel free to reach out with questions, so we may improve this tutorial!\n",
    "\n",
    "[And remember to ‚≠ê GRAPE!](https://github.com/AnacletoLAB/grape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
