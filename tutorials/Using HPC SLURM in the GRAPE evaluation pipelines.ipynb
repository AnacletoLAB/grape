{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cd33665",
   "metadata": {},
   "source": [
    "# Using HPC SLURM in the GRAPE evaluation pipelines\n",
    "\n",
    "[SLURM](https://slurm.schedmd.com/) is one of the most common systems to distribute jobs over high-performance computing (HPC) systems. For this reason, we have integrated support in the GRAPE evaluation pipelines for node-label, edge-label amd edge predictions to parallelize the computation of the different holdouts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed427f3d",
   "metadata": {},
   "source": [
    "## Parallelization logic\n",
    "The parallelization logic we adopted is relatively straighforward:\n",
    "\n",
    "1. First, we execute a preliminary step in which we retrieve the data of interest. This may include downloading graphs through the graph retrieval, for instance, so that the various SLURM nodes don't try to do that in parallel but can load the data readily.\n",
    "2. Secondly, we run the SLURM script! In this step, we actually do execute the pipeline and execute in parallel the holdouts. Do note that the number of SLURM nodes to be employed must be less or equal to the number of holdouts that you intend to run. Do not that you can execute a grid search that runs for each value a set of holdouts, just specify as number of cluster nodes to the pipeline a value that is lower or equal to the holdouts.\n",
    "3. Finally, we need to collect the results obtained by the various scripts.\n",
    "\n",
    "<img src=\"https://github.com/AnacletoLAB/grape/blob/main/images/slurm.jpg?raw=true\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226cd3f6",
   "metadata": {},
   "source": [
    "### Setting up a virtual environment\n",
    "While this is an obvious step to all SLURM users, you will most likely need to setup a virtual environment. You can do this with multiple tools, such as `conda` or `venv`. Just use the one you are more confortable with and install `grape` inside the environment by running: `pip install grape`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006cc58b",
   "metadata": {},
   "source": [
    "### Example of the data retrieval portion\n",
    "In the following code we will retrieve the STRING Homo Sapiens graph. In the bash script a bit below we will be referring to this code as `retrieve_data.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d86b388",
   "metadata": {},
   "outputs": [],
   "source": [
    "from grape.datasets.string import HomoSapiens\n",
    "\n",
    "# We download the data.\n",
    "_ = HomoSapiens()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141ecf2f",
   "metadata": {},
   "source": [
    "### Example of distributed pipeline run\n",
    "In the following section we execute the edge prediction evaluation pipeline to get the performance of an edge prediction Perceptron trained exclusively on the Jaccard Index. We will execute `NUMBER_OF_HOLDOUTS` holdouts and we expect to parallelize the task on `NUMBER_OF_SLURM_NODES` nodes. We will be referring to this code snippet as `run_pipeline.py` in the SLURM script below.\n",
    "\n",
    "Of course, within this tutorial we will get an error if we run the code snippet as we are not within a SLURM cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195e9028",
   "metadata": {},
   "outputs": [],
   "source": [
    "from grape.datasets.string import HomoSapiens\n",
    "from grape.edge_prediction import edge_prediction_evaluation, PerceptronEdgePrediction\n",
    "\n",
    "NUMBER_OF_HOLDOUTS = 10\n",
    "NUMBER_OF_SLURM_NODES= 5\n",
    "\n",
    "assert NUMBER_OF_HOLDOUTS >= NUMBER_OF_SLURM_NODES\n",
    "\n",
    "_ = edge_prediction_evaluation(\n",
    "    holdouts_kwargs=dict(train_size=0.7),\n",
    "    graphs=HomoSapiens().filter_from_ids(min_edge_weight=700),\n",
    "    models=PerceptronEdgePrediction(),\n",
    "    number_of_holdouts=NUMBER_OF_HOLDOUTS,\n",
    "    number_of_slurm_nodes=NUMBER_OF_SLURM_NODES\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df54b83",
   "metadata": {},
   "source": [
    "### Example of results collection\n",
    "Finally, in this third step, we simply collect the results that the node have computed in the various holdouts using pandas and glob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dbfd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "\n",
    "TASK_NAME = \"Edge Prediction\"\n",
    "RESULTS_PATH = \"results.csv.gz\"\n",
    "\n",
    "pd.concat([\n",
    "    pd.read_csv(path, index_col=0)\n",
    "    for path in glob(\n",
    "        \"experiments/{task_name}/*/holdout_*/*.csv.gz\".format(task_name=TASK_NAME)\n",
    "    )\n",
    "]).to_csv(RESULTS_PATH, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da41135",
   "metadata": {},
   "source": [
    "## The SLURM bash script\n",
    "One extremely important ingredient is the actual SLURM script to use to launch these jobs.\n",
    "Here is a decent generic example that you may want to use:\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=name_of_your_experiment\n",
    "#SBATCH --output=name_of_your_experiment.out\n",
    "# The number of tasks per node should always be one, as we already parallize within the pipeline.\n",
    "#SBATCH --ntasks-per-node=1\n",
    "# The number of nodes, which should be <= number of holdouts\n",
    "# This is generally the same as `NUMBER_OF_SLURM_NODES` from the `run_pipeline.py` script\n",
    "# but may be much higher when you are running some other layer of parallelization, such\n",
    "# as when you are running a grid search.\n",
    "#SBATCH --nodes=5\n",
    "# RAM to be used, just set a reasonable amount for your task\n",
    "#SBATCH --mem=16GB\n",
    "# Computation time to be used, just set a reasonable amount for your task\n",
    "#SBATCH --time 24:00:00\n",
    "# Number of processing cores to be used per node, just set a reasonable amount for your task \n",
    "#SBATCH --cpus-per-task=16\n",
    "# We want to wait for the script to complete running.\n",
    "#SBATCH --wait\n",
    "\n",
    "# Recall to activate your Python3.7+ virtual environment\n",
    "./path/to/your/virtual/environment/activate\n",
    "\n",
    "python3 retrieve_data.py\n",
    "\n",
    "for i in `seq $SLURM_NNODES`; do\n",
    "    srun --ntasks=1 --nodes=1 --exclusive python3 run_pipeline.py &\n",
    "done\n",
    "\n",
    "python3 collect_results.py\n",
    "```\n",
    "\n",
    "If we call this file `slurm_script.sh`, you can launch this script as:\n",
    "\n",
    "```bash\n",
    "sbatch slurm_script.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b2e3db",
   "metadata": {},
   "source": [
    "Good luck!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
