{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0df9a85c",
   "metadata": {},
   "source": [
    "# Billion-scale triangle count with üçá GRAPE üçá\n",
    "In this tutorial, I will show you how to use the [GRAPE library](https://github.com/AnacletoLAB/grape) to count the number of triangles in a graph. We will first compute a vertex cover of the graph using GRAPE, [as extensively covered in this previous tutorial](https://github.com/AnacletoLAB/grape/blob/main/tutorials/Billion-scale%202-approximated%20vertex%20cover%20with%20GRAPE.ipynb), and then use this vertex cover to efficiently count the triangles in the graph by using [this awesome algorithm by Oded Green and David Bader](https://davidbader.net/publication/2013-g-ba/2013-g-ba.pdf).\n",
    "\n",
    "I will explain the concept of a triangles and its importance in triangle counting, and what triangle counting is for. By the end of the tutorial, you will have a good understanding of how to use [GRAPE]((https://github.com/AnacletoLAB/grape)) to count the triangles in a graph and apply this knowledge to your projects.\n",
    "\n",
    "[Remember to ‚≠ê GRAPE!](https://github.com/AnacletoLAB/grape)\n",
    "\n",
    "### What is GRAPE?\n",
    "[üçáüçá GRAPE üçáüçá](https://github.com/AnacletoLAB/grape) is a graph processing and embedding library that enables users to easily manipulate and analyze graphs. With [GRAPE](https://github.com/AnacletoLAB/grape), users can efficiently load and preprocess graphs, generate random walks, and apply various node and edge embedding models. Additionally, [GRAPE](https://github.com/AnacletoLAB/grape) provides a fair and reproducible evaluation pipeline for comparing different graph embedding and graph-based prediction methods.\n",
    "\n",
    "![features in GRAPE](https://github.com/AnacletoLAB/grape/raw/main/images/sequence_diagram.png?raw=true)\n",
    "\n",
    "*The methods shown in the tutorial are available from the nightly version of üçá on GitHub, which we'll release on PyPI next week. (Today is 2/01/2023)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e666f1e",
   "metadata": {},
   "source": [
    "## Triangles in graphs\n",
    "In graph theory, **a triangle is a simple cycle of three vertices**. A triangle is also known as a 3-cycle.\n",
    "\n",
    "A triangle can be represented by three vertices and the three edges connecting them. For example, in the following graph:\n",
    "\n",
    "<img src=\"https://github.com/AnacletoLAB/grape/blob/main/images/triangle.jpg?raw=true\" width=200 />\n",
    "\n",
    "There is one triangle, formed by vertices `1`, `2`, and `3`. The triangle is represented by the three edges connecting these vertices: `(1,2)`, `(2,3)`, and `(3,1)`.\n",
    "\n",
    "### Why should you care about triangles?\n",
    "[Triangles](https://en.wikipedia.org/wiki/Triangle_graph) are an important concept in graph theory because they represent a basic unit of connectivity in a graph. In other words, triangles are a measure of how well connected the vertices in a graph are to each other. For example, if a graph has many triangles, it means that the vertices in the graph are well connected to each other, forming a dense and interconnected structure. On the other hand, if a graph has few triangles, it means that the vertices in the graph are less connected to each other, forming a more sparse and disconnected structure.\n",
    "\n",
    "Triangles also have several applications in various fields, including social network analysis, machine learning, and data mining."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4075c7",
   "metadata": {},
   "source": [
    "### What is triangle counting?\n",
    "The triangle count problem is the problem of counting the number of triangles in a graph. It is a subproblem of more general cycle counting problems, such as counting the number of cycles of a given length in a graph.\n",
    "\n",
    "To count the number of triangles in a graph, one must first identify all of the triangles in the graph. This can be done using various algorithms, such as brute force methods, matrix multiplication-based algorithms, and random sampling-based algorithms. Once all of the triangles in the graph have been identified, the total number of triangles can be counted by simply adding up the number of triangles identified by the algorithm.\n",
    "\n",
    "<img src=\"https://github.com/AnacletoLAB/grape/blob/main/images/triangles_in_graph.jpg?raw=true\" width=500 />\n",
    "\n",
    "#### Why should I count triangles?\n",
    "The triangle count problem has several applications in various fields, including social network analysis, machine learning, and data mining. In these fields, the number of triangles in a graph is often used as a measure of the graph's structure and connectivity. For example, in social network analysis, the number of triangles in a person's social network can be used to measure the person's [clustering coefficient](https://en.wikipedia.org/wiki/Clustering_coefficient), which is a measure of how well connected the person is to their friends. In machine learning and data mining, the triangle count problem can be used to identify patterns and trends in large data sets, and can be used for tasks such as general graphs node embedding, i.e. not specific to a single graph.\n",
    "\n",
    "We will explore in an upcoming tutorial how we can compute the clustering coefficient of large graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e746e5",
   "metadata": {},
   "source": [
    "### A good way to count triangles!\n",
    "We will be using [an efficient method to count triangles in a graph involves using a vertex cover created by Oded Green and David Bader](https://davidbader.net/publication/2013-g-ba/2013-g-ba.pdf). A vertex cover is a set of vertices such that for every edge in the graph, at least one of its endpoints is included in the vertex cover. By exploiting the properties of a vertex cover, it is possible to significantly reduce the number of intersections of adjacency lists that must be performed in order to count the triangles in a graph.\n",
    "\n",
    "[We have covered in a previous tutorial how we can compute good 2-approximated vertex covers](https://github.com/AnacletoLAB/grape/blob/main/tutorials/Billion-scale%202-approximated%20vertex%20cover%20with%20GRAPE.ipynb).\n",
    "\n",
    "The algorithm, in python pseudocode, is the following:\n",
    "\n",
    "```python\n",
    "number_of_triangles = 0\n",
    "# We can compute a vertex cover using many approaches\n",
    "# During the last tutorial, I showed a 2-approximation\n",
    "# of a minimum vertex cover.\n",
    "# I stress that the following vertex cover does not need\n",
    "# to be minimal, but the smaller it is the faster the algorithm\n",
    "# will be.\n",
    "vertex_cover = compute_vertex_cover()\n",
    "\n",
    "# We iterate over all nodes in the vertex cover\n",
    "# Of course, this iteration can be trivially\n",
    "# parallelized.\n",
    "for first in vertex_cover:\n",
    "    # We iterate over all neighbours of the current node\n",
    "    for second in neighbours(node):\n",
    "        # If the second is equal to the first node,\n",
    "        # or is not in the vertex cover we can skip\n",
    "        # over this node and continue.\n",
    "        if second == first or second not in vertex_cover:\n",
    "            continue\n",
    "        # Otherwise we can continue, and we iterate\n",
    "        # over the intersection of the first and second\n",
    "        # node neighbours.\n",
    "        for third in insersection(\n",
    "            neighbours(first),\n",
    "            neighbours(second)\n",
    "        ):\n",
    "            # We skip over the first and second\n",
    "            # nodes when we encounter them, as\n",
    "            # these would not be triangles but tuples.\n",
    "            if third == second or third == first:\n",
    "                continue\n",
    "            # Then, if also the third node is in\n",
    "            # the vertex cover, we increase the\n",
    "            # triangle count by 1 as we will encounter\n",
    "            # this node other times.\n",
    "            if third in vertex_cover:\n",
    "                number_of_triangles += 1\n",
    "            # Otherwise, we increase the count by 3,\n",
    "            # since we will not encounter this triangle\n",
    "            # other times.\n",
    "            else:\n",
    "                number_of_triangles += 3\n",
    "\n",
    "# Finally, if the graph is undirected, we \n",
    "# need to half the number of triangles as\n",
    "# we have counted all triangles twice.\n",
    "\n",
    "# We may be able to avoid this by building\n",
    "# an ad-hoc vertex cover.\n",
    "if not graph.is_directed():\n",
    "    number_of_triangles /= 2\n",
    "```\n",
    "\n",
    "The algorithm works by iterating over all vertices in the vertex cover, and for each vertex, iterating over its neighbors in the adjacency list. If the neighbor is also included in the vertex cover, the algorithm calculates the intersection of the adjacency lists of the two vertices. If the intersection contains any vertices that are also included in the vertex cover, this implies the presence of a triangle in the graph, and the algorithm increments a counter. If the intersection contains any vertices that are not included in the vertex cover, this implies the presence of three triangles in the graph, and the algorithm increments the counter by three.\n",
    "\n",
    "This approach has a worst-case time complexity of:\n",
    "\n",
    "$$O(\\lvert \\hat{V}\\rvert \\cdot \\hat{d}^2_{\\text{max}}) + \\underbrace{O(\\lvert E\\rvert)}_{\\text{Vertex cover}}$$\n",
    "\n",
    "where $\\lvert \\hat{V}\\rvert$ is the cardinality of the vertex cover, $\\hat{d}_{\\text{max}}$ is the maximum node degree in the vertex cover, and $O(\\lvert E\\rvert)$ is the time needed to find the vertex cover in a graph with $\\lvert E\\rvert$ edges. The approach can also be extended to count squares (4-circuits) and generic circuits.\n",
    "\n",
    "Overall, the use of a vertex cover to count triangles in a graph is a more efficient approach than the best known time complexity for computing the clustering coefficient, which is $O(\\lvert V \\rvert \\cdot d^2_\\text{max})$.\n",
    "\n",
    "**One think that can be explored and improved over the current algorithm, is that different approximated vertex covers may lead to different computational requirements. One important trade-off that is present here is that as a vertex cover becomes smaller and therefore the $\\lvert \\hat{V}\\rvert$ component decreases, it will necessarily contain nodes with higher degrees, and therefore $ \\hat{d}_{\\text{max}}$ will increase.**\n",
    "\n",
    "Feel free to reach out if you have ideas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de848e2",
   "metadata": {},
   "source": [
    "## Installing GRAPE\n",
    "First, we install the GRAPE library from PyPI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e5462cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install grape -qU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4c963f",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "Welcome to the experiments section of this tutorial! In this section, we will put our knowledge into practice by applying the triangles counting algorithm on four different graphs: the [KGCOVID19 knowledge graph](https://www.cell.com/patterns/fulltext/S2666-3899(20)30203-8?_returnURL=https%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS2666389920302038%3Fshowall%3Dtrue), the [Friendster graph](https://networkrepository.com/friendster.php), the [ClueWeb09 web graph](https://networkrepository.com/web-ClueWeb09.php), and [the WikiData graph](https://www.wikidata.org/wiki/Wikidata:Main_Page).\n",
    "\n",
    "We run these experiments on a machine with 24 threads and 12 cores.\n",
    "\n",
    "**Do note that, for the limits of memory of my desktop, I will restart the jupyter after running the experiment on each of the large graphs.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fb6fdc",
   "metadata": {},
   "source": [
    "In my machine I only have 24 threads. You can estimate the expected computation time by interpolating the time estimates on 24 threads and the amount you have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00549fe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2253bbb",
   "metadata": {},
   "source": [
    "Also, this machine has about `128GB` of RAM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cc9ed99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125.7063217163086"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import psutil\n",
    "    \n",
    "psutil.virtual_memory().total / 1024**3 # total physical memory in Bytes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15280e49",
   "metadata": {},
   "source": [
    "### KGCOVID19\n",
    "We kick off our experiments with a relatively small graph, considering the sizes of the networks we will tackle by the end of it: KGCOVID19, with `574K` nodes and `18M` edges.\n",
    "\n",
    "#### What is KGCOVID19?\n",
    "[KGCOVID19](https://doi.org/10.1016%2Fj.patter.2020.100155) is a framework for producing knowledge graphs (KGs) that integrate and integrate biomedical data related to the COVID-19 pandemic. The framework is designed to be flexible and customizable, allowing researchers to create KGs for different downstream applications, including machine learning tasks, hypothesis-based querying, and browsable user interfaces for exploring and discovering relationships in COVID-19 data. The goal of KGCOVID19 is to provide an up-to-date, integrated source of data on SARS-CoV-2 and related viruses, including SARS-CoV and MERS-CoV, to support the biomedical research community in its efforts to respond to the COVID-19 pandemic. The framework can also be applied to other situations where siloed biomedical data must be quickly integrated for various research purposes, including future pandemics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c0b685e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32.1 s, sys: 3.81 s, total: 35.9 s\n",
      "Wall time: 12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from grape.datasets.kghub  import KGCOVID19\n",
    "\n",
    "kgcovid19 = KGCOVID19()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5901df14",
   "metadata": {},
   "source": [
    "We display the number of nodes, `574K` and of undirected edges `18M`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "878ffc06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(574232, 18251238)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kgcovid19.get_number_of_nodes(), kgcovid19.get_number_of_edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55921909",
   "metadata": {},
   "source": [
    "And now we compute a number of triangles of KGCOVID19."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c35198a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 24s, sys: 738 ms, total: 2min 25s\n",
      "Wall time: 6.28 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1208845416"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "kgcovid19.get_number_of_triangles()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e382158f",
   "metadata": {},
   "source": [
    "And done! Just a few seconds! Over $1$ billion triangles!\n",
    "\n",
    "<img src=\"https://github.com/AnacletoLAB/grape/blob/main/images/one_billion_triangles.jpeg?raw=true\" width=300 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3270c2a9",
   "metadata": {},
   "source": [
    "### Friendster\n",
    "[Friendster](https://en.wikipedia.org/wiki/Friendster) was a social networking service launched in 2002. It was one of the first social networking sites and was popular in the early 2000s. The site allowed users to connect with friends and meet new people through the use of personal profiles and networks of friends. Friendster was initially successful but eventually faced competition from more recent social networking sites such as MySpace and Facebook. In 2011, the company announced that it was transitioning from a social networking site to a social gaming site, and in 2015 it was acquired by a Malaysian company.\n",
    "\n",
    "#### What is the network repository?\n",
    "[Network Repository](https://networkrepository.com/index.php) is a scientific network data repository that provides interactive visualization and mining tools for analyzing and exploring network data. It is the first interactive repository of its kind. Network Repository is intended to facilitate scientific research on networks by making it easier for researchers to access and analyze an extensive network data collection. It is a valuable resource for researchers in various fields, including network science, bioinformatics, machine learning, data mining, physics, and social science."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f30b201",
   "metadata": {},
   "source": [
    "#### ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è WARNING: Make sure you have enough disk space! ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è\n",
    "*Please be aware that this graph is not small and requires a significant amount of disk space to store and work with. Before proceeding with the tutorial, ensure you have enough free space on your hard drive or other storage devices to accommodate the size of the graph. If you do not have sufficient space, you may encounter errors or other issues when downloading or working with the graph. It is important to ensure that you have enough space available before proceeding. If necessary, consider freeing up additional space on your device to make room for the graph.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afafaae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97G\t/bfd/graphs/networkrepository/SocFriendster\r\n"
     ]
    }
   ],
   "source": [
    "!du -sh /bfd/graphs/networkrepository/SocFriendster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f15366b",
   "metadata": {},
   "source": [
    "In the next cell we retrieve and load the Friendster dataset from GRAPE, dataset from the [network repository](https://networkrepository.com/index.php).. Do note that we are configuring it to not load the node names and edge types in order to conserve memory. The cell also includes a directive to measure and display the execution time of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb5927ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44min 17s, sys: 53.8 s, total: 45min 11s\n",
      "Wall time: 5min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from grape.datasets.networkrepository import SocFriendster\n",
    "\n",
    "friendster = SocFriendster(\n",
    "    # We cannot load the node names, as the would require too much memory\n",
    "    # for my poor old desktop.\n",
    "    load_nodes=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30f59e5",
   "metadata": {},
   "source": [
    "We display the number of nodes, `65.6M`, and of undirected edges, `1.8G`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdbee4bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65608366, 1806067135)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "friendster.get_number_of_nodes(), friendster.get_number_of_edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220ae65d",
   "metadata": {},
   "source": [
    "We compute the number of triangles in Friendster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f5950fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2h 53min 45s, sys: 20.6 s, total: 2h 54min 6s\n",
      "Wall time: 7min 50s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12521172426"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "friendster.get_number_of_triangles()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ede35d",
   "metadata": {},
   "source": [
    "A bit slower, but considering we are already in the billions of edges not too bad! $12$ billion triangles!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5074f7bb",
   "metadata": {},
   "source": [
    "### ClueWeb\n",
    "[The ClueWeb09 dataset](http://lemurproject.org/clueweb09/) was created to support research on information retrieval and related human language technologies; it consists of about `1.7` billion web pages that were collected in January and February 2009 and the roughly `8` billion undirected links.\n",
    "\n",
    "It is used for research on information retrieval and related human language technologies and is used by several tracks of the TREC conference. The dataset includes web pages in various languages and a web graph that includes unique URLs and total outlinks for the entire dataset and for a subset called TREC Category B (the first 50 million English pages). The ClueWeb09 dataset and subsets are distributed in different formats, including as tarred/gzipped files on hard disk drives and as a subset that is downloaded from the web. The Lemur Project provides online services for searching and interacting with the ClueWeb09 dataset, including an Indri search engine for searching the English and Japanese subsets and Wikipedia, as well as a batch query service and an attribute lookup service. The Lemur Project also offers hosted copies of the ClueWeb09 dataset for organizations that have licenses to use it.\n",
    "\n",
    "*We also retrieve this graph from [Network Repository](https://networkrepository.com/index.php)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4ca962",
   "metadata": {},
   "source": [
    "#### ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è This is a big graph! Make sure you have the disk space! ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è\n",
    "*This is a warning to ensure that users have sufficient disk space before downloading and using a large graph. It is important to ensure that you have enough space on your hard drive or another storage device to accommodate the graph size, as attempting to download or work with a graph that is too large for your available space can lead to errors and other issues. It is advisable to check your available disk space before downloading or working with a large graph and free up additional space if necessary.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a437d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "631G\t/bfd/graphs/networkrepository/WebClueweb09/\r\n"
     ]
    }
   ],
   "source": [
    "!du -sh /bfd/graphs/networkrepository/WebClueweb09/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9525bb",
   "metadata": {},
   "source": [
    "In the following cell we retrieve and load the `Clueweb09` dataset from the [network repository](https://networkrepository.com/index.php). We configure it to not load the node names in order to conserve memory. The cell also includes a directive to measure and display the execution time of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e6a8aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3h 2min 51s, sys: 6min 59s, total: 3h 9min 50s\n",
      "Wall time: 37min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from grape.datasets.networkrepository import WebClueweb09\n",
    "\n",
    "clueweb = WebClueweb09(\n",
    "    # We cannot load the node names, as the would require too much memory\n",
    "    # for my poor old desktop.\n",
    "    load_nodes=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0743a6c8",
   "metadata": {},
   "source": [
    "We display the number of nodes, `1.68G`, and of undirected edges, `7.8G`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ea0be87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1684868322, 7811385827)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clueweb.get_number_of_nodes(), clueweb.get_number_of_edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1198087a",
   "metadata": {},
   "source": [
    "We compute the number of triangles of ClueWeb. Here we start with the heavy weights!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45575c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7d 17h 41min 32s, sys: 28min 38s, total: 7d 18h 10min 11s\n",
      "Wall time: 8h 36min 37s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "93039057369"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clueweb.get_number_of_triangles()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d83891a",
   "metadata": {},
   "source": [
    "DAMN! That's a big graph! $93$ billion triangles! No wonder it took 8 hours even for this algorithm!\n",
    "\n",
    "<img src=\"https://media.tenor.com/T42cqp6YKEEAAAAC/damn-damn-damn-damn.gif\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c84125c",
   "metadata": {},
   "source": [
    "## WikiData\n",
    "[WikiData](https://www.wikidata.org/wiki/Wikidata:Main_Page) is a collaborative, multilingual, free knowledge base that can be read and edited by humans and machines. It provides structured data representing the relationships between concepts and entities, including real-world objects, events, ideas and abstract concepts. The data in WikiData is organized into a graph structure, with nodes representing concepts or entities and edges representing relationships between them. For example, a node for the idea \"dog\" might be connected to other nodes representing specific dog breeds, such as \"Labrador Retriever\" or \"Poodle,\" through edges that define the relationship \"breed of.\"\n",
    "\n",
    "The WikiData graph is constantly growing and changing as users contribute new data and edit existing data. It is based on a flexible data model that allows for creation of new properties and classes to represent the relationships between concepts and entities. The WikiData graph is used in various applications, including data integration, natural language processing, and machine learning. It also provides structured data for Wikipedia and other Wikimedia projects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3f7fe8",
   "metadata": {},
   "source": [
    "#### ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è This is a big graph! Make sure you have the disk space! ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è\n",
    "*This is a warning to ensure that users have sufficient disk space before downloading and using a large graph. It is important to ensure that you have enough space on your hard drive or another storage device to accommodate the graph size, as attempting to download or work with a graph that is too large for your available space can lead to errors and other issues. It is advisable to check your available disk space before downloading or working with a large graph and free up additional space if necessary.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8010181d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,7T\t/bfd/graphs/wikidata/WikiData\r\n"
     ]
    }
   ],
   "source": [
    "!du -sh /bfd/graphs/wikidata/WikiData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab979081",
   "metadata": {},
   "source": [
    "In the next cell we retrieve and load the WikiData dataset from GRAPE, directly from [WikiData's website](https://www.wikidata.org/wiki/Wikidata:Main_Page). Do note that we are configuring it to not load the node names and edge types in order to conserve memory. The cell also includes a directive to measure and display the execution time of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1b8b27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2h 1min 1s, sys: 5min 21s, total: 2h 6min 22s\n",
      "Wall time: 20min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from grape.datasets.wikidata import WikiData\n",
    "\n",
    "wikidata = WikiData(\n",
    "    # We cannot load the node names, as the would require too much memory\n",
    "    # for my poor old desktop.\n",
    "    load_nodes=False,\n",
    "    # Same thing for the edge types.\n",
    "    load_edge_types=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033dc051",
   "metadata": {},
   "source": [
    "We display the number of nodes, `1.29G` and of undirected edges `5G`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ee9bc66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1294126247, 5040170396)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikidata.get_number_of_nodes(), wikidata.get_number_of_edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714b43a1",
   "metadata": {},
   "source": [
    "Here, we try to compute the number of triangles of WikiData."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692c5296",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "wikidata.get_number_of_triangles()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7887da4e",
   "metadata": {},
   "source": [
    "After over two days of computation, this one was still running, so I had to kill it. [We know from the previous tutorial on computing an approximated vertex cover on WikiData](https://github.com/AnacletoLAB/grape/blob/main/tutorials/Billion-scale%202-approximated%20vertex%20cover%20with%20GRAPE.ipynb) that we can quickly compute a vertex cover with only $16\\%$ of WikiData's nodes, roughly with the same number of nodes as ClueWeb's, and WikiData has less edges than ClueWeb. This means that, most likely, WikiData just has much more triangles than ClueWeb and therefore intersections between the first and second order neighbourhoods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94c3cab",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "In this tutorial, we learned how to use the [GRAPE](https://github.com/AnacletoLAB/grape) library to compute the exact number of triangles in large graphs. We discussed what is a triangle, and why counting triangles can be useful. Also, we illustrated an algorithm for computing triangles using an approximated vertex cover.\n",
    "\n",
    "I hope you now have a better grasp on computing triangles and how to use GRAPE to compute them for your projects. Do feel free to reach out with any questions or feedback, as I always look for ways to improve this tutorial.\n",
    "\n",
    "[And remember to ‚≠ê GRAPE!](https://github.com/AnacletoLAB/grape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
